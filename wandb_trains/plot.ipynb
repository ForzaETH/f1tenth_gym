{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import yaml\n",
    "import gpytorch\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_PATH_DATA = \"/home/eghignone/pbl-f1tenth-gym/wandb_trains/pre_trained_models/GLC_pit_rbring1/it1/no_vy/noisestate_velOptFalse_jerkp20000\"\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        \n",
    "def analyze_data(file_path: str, \n",
    "                 verbose: bool = False):\n",
    "    # load yaml file\n",
    "    with open(f\"{file_path}/eval_sim/recorder_config.yaml\", 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    time_stamp = str(config[\"last_time_stamp\"])\n",
    "\n",
    "    # setup folders\n",
    "    data_folder = f\"{ABS_PATH_DATA}/eval_sim/F110_recordings/{time_stamp}\"\n",
    "    data_path = f\"{data_folder}/car_raw_info.csv\"\n",
    "    traj_path = f\"{data_folder}/traj.npy\"\n",
    "    save_path = f\"{ABS_PATH_DATA}/eval_sim/eval_plots/\"\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        print(f\"Creating folder for saving data here: {save_path}\") if verbose else None\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "    data = pd.read_csv(data_path, header=0, sep=\"\\t\")\n",
    "\n",
    "\n",
    "    # read raceline data\n",
    "    raceline = np.load(traj_path)\n",
    "    print(f\"{raceline.shape = }\") if verbose else None\n",
    "\n",
    "    raceline_length = np.linalg.norm(raceline[1:, :] - raceline[:-1, :], axis=1).sum()\n",
    "    print(f\"{raceline_length = :.3f}\") if verbose else None\n",
    "    \n",
    "    # some preprocessing\n",
    "\n",
    "    ## create column with modulo on frenet s \n",
    "    data[\"frenet_s_mod\"] = data[\"frenet_s\"].copy()\n",
    "    data[\"frenet_s_mod\"] %= raceline_length\n",
    "\n",
    "    # fit a GP to the data, to obtain a smoother estimate of the RL speed input\n",
    "    # first prepare the data, by padding the velocity profile with repeated values to make it periodic\n",
    "    velocities = data[\"speed_input\"].values\n",
    "    frenet_positions = data[\"frenet_s_mod\"].values\n",
    "\n",
    "    # repeat all data points where freent is higher than half the track length\n",
    "    mask = frenet_positions > raceline_length / 2\n",
    "    frenet_positions_before = frenet_positions[mask] - raceline_length\n",
    "    frenet_positions = np.concatenate([frenet_positions, frenet_positions_before])\n",
    "    velocities = np.concatenate([velocities, velocities[mask]])\n",
    "    # same but after \n",
    "    mask = frenet_positions < raceline_length / 2\n",
    "    frenet_positions_after = frenet_positions[mask] + raceline_length\n",
    "    frenet_positions = np.concatenate([frenet_positions, frenet_positions_after])\n",
    "    velocities = np.concatenate([velocities, velocities[mask]])\n",
    "\n",
    "    # initialize likelihood and model\n",
    "    print(\"Initializing GP model\") if verbose else None\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(\n",
    "        torch.from_numpy(frenet_positions).float(),\n",
    "        torch.from_numpy(velocities).float(),\n",
    "        likelihood\n",
    "    )\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the adam optimizer\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "    ], lr=0.1)\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    training_iter = 5\n",
    "    for i in tqdm(range(training_iter)):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(torch.from_numpy(frenet_positions).float())\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, torch.from_numpy(velocities).float())\n",
    "        loss.backward()\n",
    "        print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item())) if verbose else None\n",
    "        optimizer.step()\n",
    "\n",
    "    # Get into evaluation (predictive posterior) mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Test points are regularly spaced along [0, raceline_length]\n",
    "    test_x = torch.linspace(0, raceline_length, 1000)\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x.float()))\n",
    "        dataset_pred = likelihood(model(torch.from_numpy(data[\"frenet_s_mod\"].to_numpy().astype(np.float32))))\n",
    "        lower, upper = observed_pred.confidence_region()    \n",
    "    \n",
    "    print(\"GP model trained\") if verbose else None\n",
    "\n",
    "    # plot the results only in range [0, raceline_length]\n",
    "    plotting_mask_pred = (test_x >= 0) & (test_x <= raceline_length)\n",
    "\n",
    "    # assess filtered data with a simple two-line-implementation exponential filter\n",
    "\n",
    "    def filter(alpha):\n",
    "        \"\"\"Filter the speed_input with an exponential filter\"\"\"\n",
    "        data[\"speed_input_filtered\"] = data[\"speed_input\"].copy()\n",
    "        filter = lambda x, y: alpha * x + (1 - alpha) * y\n",
    "        for i in range(1, len(data)):\n",
    "            data.at[i, \"speed_input_filtered\"] = filter(data.at[i, \"speed_input\"], data.at[i-1, \"speed_input_filtered\"])\n",
    "            \n",
    "        # create copy of sorted data to plot\n",
    "        data_sorted = data.sort_values(\"frenet_s_mod\")\n",
    "        sorted_s = data_sorted[\"frenet_s_mod\"].values\n",
    "        sorted_filtered = data_sorted[\"speed_input_filtered\"].values\n",
    "        \n",
    "        return sorted_s.copy(), sorted_filtered.copy()\n",
    "    \n",
    "    alphas = np.linspace(0.3, 0.6, 7)\n",
    "    \n",
    "    ## FIRST PLOT: assessment on the filter's delay\n",
    "    fig, axs = plt.subplots(len(alphas), 1, figsize=(20, 40))\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        sorted_s, sorted_filtered = filter(alpha)\n",
    "        axs[i].plot(sorted_s, sorted_filtered, label=f\"{alpha = }\", alpha=0.5)\n",
    "        axs[i].plot(test_x[plotting_mask_pred].numpy(), observed_pred.mean[plotting_mask_pred].numpy(), 'b')\n",
    "        axs[i].fill_between(test_x[plotting_mask_pred].numpy(), lower[plotting_mask_pred].numpy(), upper[plotting_mask_pred].numpy(), alpha=0.5)\n",
    "        axs[i].set_ylim([0, 10])\n",
    "        axs[i].legend(['Causally Filtered Input Data', 'GP Regressed Mean', 'GP Regressed Variance'])\n",
    "        axs[i].grid()\n",
    "        axs[i].set_title(f\"{alpha = :.2f}\")\n",
    "        axs[i].set_xlabel(r\"Frenet $s$ coordinate [m]\")\n",
    "        axs[i].set_ylabel(r\"Speed [m/s]\")\n",
    "    \n",
    "    # save the figure\n",
    "    fig.savefig(f\"{save_path}/filter_assessment.png\", bbox_inches='tight', pad_inches=0.1, dpi=300, transparent=False, facecolor='white')\n",
    "    print(\"Filter assessment figure saved\") if verbose else None\n",
    "    \n",
    "    #plot velocities against s_mod\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), facecolor='white')\n",
    "    # plot gray with alpha 0.3\n",
    "    ax.plot(data[\"frenet_s_mod\"], data[\"speed\"], 'k.', alpha=0.3, label=\"speed measured\")\n",
    "\n",
    "    # plot pp speed input too\n",
    "    ax.plot(data[\"frenet_s_mod\"], data[\"speed_input_pp\"], 'r.', alpha=1, label=\"speed input pp\", zorder=-10)\n",
    "\n",
    "    # plot GP regressed speed input\n",
    "    ax.plot(data[\"frenet_s_mod\"], dataset_pred.mean.numpy() + data[\"speed_input_pp\"], 'b.', label=\"speed input GP\")\n",
    "\n",
    "    # plot filtered speed input\n",
    "    sorted_s, sorted_filtered = filter(0.5)\n",
    "    sorted_pp = data.sort_values(\"frenet_s_mod\")[\"speed_input_pp\"].values\n",
    "    ax.plot(sorted_s, sorted_filtered + sorted_pp, 'purple', alpha=0.3, label=\"speed input filtered\")\n",
    "    # use diamond markers \n",
    "        \n",
    "        \n",
    "    # plot total \n",
    "    ax.plot(data[\"frenet_s_mod\"], data[\"speed_input\"] + data[\"speed_input_pp\"], 'g.', alpha=0.3, label=\"speed total\")\n",
    "\n",
    "    # add legend outisde of plot\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # label x axis\n",
    "    ax.set_xlabel(r\"Frenet $s$ coordinate [m]\")\n",
    "\n",
    "    # add grid\n",
    "    ax.grid()\n",
    "\n",
    "    # save with background\n",
    "    fig.savefig(f\"{save_path}/speed_against_s_mod.png\", bbox_inches='tight', pad_inches=0.1, dpi=300, transparent=False, facecolor='white')\n",
    "    print(\"Speed against frenet s coordinate figure saved\") if verbose else None\n",
    "    \n",
    "    # plot similar modulo statistics but for steer\n",
    "    fig, ax = plt.subplots(figsize=(20, 10), facecolor='white')\n",
    "    # plot gray with alpha 0.3\n",
    "    ax.plot(data[\"frenet_s_mod\"], data[\"yaw_angle\"], 'k.', alpha=0.3, label=\"steer measured\")\n",
    "\n",
    "    # plot pp speed input too\n",
    "    ax.plot(data[\"frenet_s_mod\"], data[\"steering_input_pp\"], 'r.', alpha=1, label=\"steer input pp\", zorder=-10)\n",
    "\n",
    "    # plot totalsteer_input in blue\n",
    "    ax.plot(data[\"frenet_s_mod\"], data[\"steering_input\"]+data[\"steering_input_pp\"], 'b.', alpha=0.3, label=\"steer input rl\")\n",
    "\n",
    "    ax.grid()\n",
    "    # legend outside\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # label x axis\n",
    "    ax.set_xlabel(r\"Frenet $s$ coordinate [m]\")\n",
    "    \n",
    "    # label y axis\n",
    "    ax.set_ylabel(r\"Steer input [rad]\")\n",
    "    \n",
    "    # plot total\n",
    "    fig.savefig(f\"{save_path}/steer_input.png\", dpi=300)\n",
    "    print(\"Steer input figure saved\") if verbose else None\n",
    "    \n",
    "    # read lap times\n",
    "\n",
    "    with open(f\"{data_folder}/lap_time_list.txt\", 'r') as f:\n",
    "        lap_times = f.readline()\n",
    "    lap_times = lap_times.strip(\"[]\").split(\",\")\n",
    "    lap_times = [float(lap_time) for lap_time in lap_times]\n",
    "\n",
    "    print(\"Saving lap statistics\") if verbose else None\n",
    "    with open(f\"{save_path}/report.txt\", \"w\") as file:\n",
    "        file.write(f\"Report for the model at {data_path}, with timestamp {time_stamp}\\n\")\n",
    "        file.write(f\"avg lap time = {np.mean(lap_times):.3f} s\\n\")\n",
    "        file.write(f\"Average lateral deviation: {data['frenet_d'].abs().mean():.3f} m\\n\")\n",
    "        file.write(f\"Max velocity: {data['speed'].max():.3f} m/s\\n\")\n",
    "    \n",
    "    print(\"Data analyzed and saved to disk\")\n",
    "analyze_data(ABS_PATH_DATA, verbose=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raceline data\n",
    "\n",
    "raceline = np.load(traj_path)\n",
    "print(f\"{raceline.shape = }\")\n",
    "print(f\"{raceline[:3, :] = }\")\n",
    "\n",
    "raceline_length = np.linalg.norm(raceline[1:, :] - raceline[:-1, :], axis=1).sum()\n",
    "print(f\"{raceline_length = :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot raceline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(raceline[:, 0], raceline[:, 1], 'r-')\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "plt.plot(data[\"pos_x\"], data[\"pos_y\"], 'b.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some preprocessing\n",
    "\n",
    "## create column with modulo on frenet s \n",
    "data[\"frenet_s_mod\"] = data[\"frenet_s\"].copy()\n",
    "data[\"frenet_s_mod\"] %= raceline_length\n",
    "\n",
    "# fit a piecewise linear function to the velocity profile\n",
    "\n",
    "## first prepare the data, by padding the velocity profile with repeated values to make it periodic\n",
    "velocities = data[\"speed_input\"].values\n",
    "frenet_positions = data[\"frenet_s_mod\"].values\n",
    "\n",
    "# repeat all data points where freent is higher than half the track length\n",
    "mask = frenet_positions > raceline_length / 2\n",
    "frenet_positions_before = frenet_positions[mask] - raceline_length\n",
    "frenet_positions = np.concatenate([frenet_positions, frenet_positions_before])\n",
    "velocities = np.concatenate([velocities, velocities[mask]])\n",
    "# same but after \n",
    "mask = frenet_positions < raceline_length / 2\n",
    "frenet_positions_after = frenet_positions[mask] + raceline_length\n",
    "frenet_positions = np.concatenate([frenet_positions, frenet_positions_after])\n",
    "velocities = np.concatenate([velocities, velocities[mask]])\n",
    "\n",
    "# TODO somehow handle the data\n",
    "\n",
    "import gpytorch\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# fit a GP to the data\n",
    "# we will use a rbf kernel with white noise\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(\n",
    "    torch.from_numpy(frenet_positions).float(),\n",
    "    torch.from_numpy(velocities).float(),\n",
    "    likelihood\n",
    ")\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 50\n",
    "\n",
    "for i in tqdm(range(training_iter)):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(torch.from_numpy(frenet_positions).float())\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, torch.from_numpy(velocities).float())\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iter, loss.item()))\n",
    "    optimizer.step()\n",
    "    \n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test points are regularly spaced along [0, raceline_length]\n",
    "test_x = torch.linspace(0, raceline_length, 1000)\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x.float()))\n",
    "    dataset_pred = likelihood(model(torch.from_numpy(data[\"frenet_s_mod\"].to_numpy().astype(np.float32))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results only in range [0, raceline_length]\n",
    "plotting_mask_data = (frenet_positions >= 0) & (frenet_positions <= raceline_length)\n",
    "plotting_mask_pred = (test_x >= 0) & (test_x <= raceline_length)\n",
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as shaded dots\n",
    "    ax.plot(frenet_positions[plotting_mask_data], velocities[plotting_mask_data], 'r.')    \n",
    "    \n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x[plotting_mask_pred].numpy(), observed_pred.mean[plotting_mask_pred].numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x[plotting_mask_pred].numpy(), lower[plotting_mask_pred].numpy(), upper[plotting_mask_pred].numpy(), alpha=0.5)\n",
    "    ax.set_ylim([0, 10])\n",
    "    ax.legend(['RL residual speed action', 'Mean', 'Confidence'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instroduce causal filtering to assess delay amount\n",
    "# we will use a causal exponential filter\n",
    "\n",
    "def filter(alpha):\n",
    "    data[\"speed_input_filtered\"] = data[\"speed_input\"].copy()\n",
    "    filter = lambda x, y: alpha * x + (1 - alpha) * y\n",
    "    for i in range(1, len(data)):\n",
    "        data.at[i, \"speed_input_filtered\"] = filter(data.at[i, \"speed_input\"], data.at[i-1, \"speed_input_filtered\"])\n",
    "        \n",
    "    # create copy of sorted data to plot\n",
    "    data_sorted = data.sort_values(\"frenet_s_mod\")\n",
    "    sorted_s = data_sorted[\"frenet_s_mod\"].values\n",
    "    sorted_filtered = data_sorted[\"speed_input_filtered\"].values\n",
    "    \n",
    "    return sorted_s.copy(), sorted_filtered.copy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a number of subplots related to alphas \n",
    "# for each subplot, plot the filtered velocity profile and the GP prediction\n",
    "\n",
    "alphas = np.linspace(0.3, 0.6, 7)\n",
    "\n",
    "fig, axs = plt.subplots(len(alphas), 1, figsize=(20, 40))\n",
    "for i, alpha in enumerate(alphas):\n",
    "    sorted_s, sorted_filtered = filter(alpha)\n",
    "    axs[i].plot(sorted_s, sorted_filtered, label=f\"{alpha = }\", alpha=0.5)\n",
    "    axs[i].plot(test_x[plotting_mask_pred].numpy(), observed_pred.mean[plotting_mask_pred].numpy(), 'b')\n",
    "    axs[i].fill_between(test_x[plotting_mask_pred].numpy(), lower[plotting_mask_pred].numpy(), upper[plotting_mask_pred].numpy(), alpha=0.5)\n",
    "    axs[i].set_ylim([0, 10])\n",
    "    axs[i].legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    axs[i].grid()\n",
    "    axs[i].set_title(f\"{alpha = :.2f}\")\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot velocities against s_mod\n",
    "\n",
    "plt.Figure(figsize=(10, 10), facecolor='white')\n",
    "# plot gray with alpha 0.3\n",
    "plt.plot(data[\"frenet_s_mod\"], data[\"speed\"], 'k.', alpha=0.3, label=\"speed measured\")\n",
    "\n",
    "# plot pp speed input too\n",
    "plt.plot(data[\"frenet_s_mod\"], data[\"speed_input_pp\"], 'r.', alpha=0.3, label=\"speed input pp\")\n",
    "\n",
    "# plot GP regressed speed input\n",
    "plt.plot(data[\"frenet_s_mod\"], dataset_pred.mean.numpy() + data[\"speed_input_pp\"], 'b.', label=\"speed input GP\")\n",
    "\n",
    "# plot filtered speed input\n",
    "sorted_s, sorted_filtered = filter(0.5)\n",
    "sorted_pp = data.sort_values(\"frenet_s_mod\")[\"speed_input_pp\"].values\n",
    "plt.plot(sorted_s, sorted_filtered + sorted_pp, 'y.', alpha=0.3, label=\"speed input filtered\")    \n",
    "    \n",
    "# plot total \n",
    "plt.plot(data[\"frenet_s_mod\"], data[\"speed_input\"] + data[\"speed_input_pp\"], 'g.', alpha=0.3, label=\"speed total\")\n",
    "\n",
    "# add legend outisde of plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# white background\n",
    "plt.gca().set_facecolor('white')\n",
    "\n",
    "# label x axis\n",
    "plt.xlabel(r\"Frenet $s$ coordinate [m]\")\n",
    "\n",
    "# add grid\n",
    "plt.grid()\n",
    "\n",
    "# save with background\n",
    "plt.savefig(f\"{save_path}/speed_against_s_mod.svg\", bbox_inches='tight', pad_inches=0.1, dpi=300, transparent=False, facecolor='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot similar modulo staitstics but for steer\n",
    "\n",
    "plt.Figure(figsize=(20, 10))\n",
    "# plot gray with alpha 0.3\n",
    "plt.plot(data[\"frenet_s_mod\"], data[\"yaw_angle\"], 'k.', alpha=0.3, label=\"steer measured\")\n",
    "\n",
    "# plot pp speed input too\n",
    "plt.plot(data[\"frenet_s_mod\"], data[\"steering_input_pp\"], 'r.', alpha=0.3, label=\"steer input pp\")\n",
    "\n",
    "# plot totalsteer_input in blue\n",
    "plt.plot(data[\"frenet_s_mod\"], data[\"steering_input\"]+data[\"steering_input_pp\"], 'b.', alpha=0.3, label=\"steer input rl\")\n",
    "\n",
    "# make figure huge\n",
    "# plot total\n",
    "plt.savefig(f\"{save_path}/steer_input.png\", dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lap times\n",
    "\n",
    "with open(f\"{data_folder}/lap_time_list.txt\", 'r') as f:\n",
    "    lap_times = f.readline()\n",
    "lap_times = lap_times.strip(\"[]\").split(\",\")\n",
    "lap_times = [float(lap_time) for lap_time in lap_times]\n",
    "\n",
    "with open(f\"{save_path}/report.txt\", \"w\") as file:\n",
    "    file.write(f\"Report for the model at {data_path}, with timestamp {time_stamp}\\n\")\n",
    "    file.write(f\"avg lap time = {np.mean(lap_times):.3f} s\\n\")\n",
    "    file.write(f\"Average lateral deviation: {data['frenet_d'].abs().mean():.3f} m\\n\")\n",
    "    file.write(f\"Max velocity: {data['speed'].max():.3f} m/s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1tenth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
